{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HasSBvzb3YPX"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./cleaning_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mty4tYxA4QtW"
   },
   "outputs": [],
   "source": [
    "def process_week_data(week_number, plays):\n",
    "\n",
    "  # -- defining function to read in all data & apply cleaning functions\n",
    "\n",
    "  file_path = f\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/raw/tracking_week_{week_number}.csv\"\n",
    "  week = pd.read_csv(file_path)\n",
    "  print(f\"Finished reading Week {week_number} data\")\n",
    "\n",
    "\n",
    "  # applying cleaning functions\n",
    "  week = rotate_direction_and_orientation(week)\n",
    "  week = make_plays_left_to_right(week)\n",
    "  week = calculate_velocity_components(week)\n",
    "  week = pass_attempt_merging(week, plays)\n",
    "  # week = label_offense_defense_coverage(week, plays)  # for specific coverage... currently set to man/zone only\n",
    "  week = label_offense_defense_manzone(week, plays)\n",
    "\n",
    "  week['week'] = week_number\n",
    "  week['uniqueId'] = week['gameId'].astype(str) + \"_\" + week['playId'].astype(str)\n",
    "  week['frameUniqueId'] = (\n",
    "      week['gameId'].astype(str) + \"_\" +\n",
    "      week['playId'].astype(str) + \"_\" +\n",
    "      week['frameId'].astype(str))\n",
    "\n",
    "  # adding frames_from_snap (to do: make this a function but fine for now)\n",
    "  snap_frames = week[week['frameType'] == 'SNAP'].groupby('uniqueId')['frameId'].first()\n",
    "  week = week.merge(snap_frames.rename('snap_frame'), on='uniqueId', how='left')\n",
    "  week['frames_from_snap'] = week['frameId'] - week['snap_frame']\n",
    "\n",
    "  # filtering only for even frames\n",
    "  week = week[week['frameId'] % 2 == 0]\n",
    "\n",
    "  # ridding of noisier outliers out of scope (15 seconds after the snap)\n",
    "  week = week[(week['frames_from_snap'] >= -150) & (week['frames_from_snap'] <= 50)]\n",
    "\n",
    "  # applying data augmentation to increase training size (centered around 0-4 seconds presnap!)\n",
    "  # -- 1/3rd of the current num of frames... specifically selecting for frames around the snap\n",
    "\n",
    "  num_unique_frames = len(set(week['frameUniqueId']))\n",
    "  selected_frames = select_augmented_frames(week, int(num_unique_frames / 3), sigma=5)\n",
    "  week_aug = data_augmentation(week, selected_frames)\n",
    "\n",
    "  week = pd.concat([week, week_aug])\n",
    "\n",
    "  print(f\"Finished processing Week {week_number} data\")\n",
    "  print()\n",
    "\n",
    "  return week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403953,
     "status": "ok",
     "timestamp": 1733766584694,
     "user": {
      "displayName": "Poker Vision",
      "userId": "17516040938073675309"
     },
     "user_tz": 300
    },
    "id": "q9hA3htK3XIH",
    "outputId": "c35025a1-e2b2-4431-9b0b-a3fdf771936d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading Week 1 data\n",
      "Finished processing Week 1 data\n",
      "\n",
      "Finished reading Week 2 data\n",
      "Finished processing Week 2 data\n",
      "\n",
      "Finished reading Week 3 data\n",
      "Finished processing Week 3 data\n",
      "\n",
      "Finished reading Week 4 data\n",
      "Finished processing Week 4 data\n",
      "\n",
      "Finished reading Week 5 data\n",
      "Finished processing Week 5 data\n",
      "\n",
      "Finished reading Week 6 data\n",
      "Finished processing Week 6 data\n",
      "\n",
      "Finished reading Week 7 data\n",
      "Finished processing Week 7 data\n",
      "\n",
      "Finished reading Week 8 data\n",
      "Finished processing Week 8 data\n",
      "\n",
      "Finished reading Week 9 data\n",
      "Finished processing Week 9 data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#from google.colab import drive\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# reading static CSV files (currently in GDrive)\n",
    "games = pd.read_csv(\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/raw/games.csv\")\n",
    "player_play = pd.read_csv(\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/raw/player_play.csv\")\n",
    "players = pd.read_csv(\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/raw/players.csv\")\n",
    "plays = pd.read_csv(\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/raw/plays.csv\")\n",
    "\n",
    "all_weeks = []\n",
    "\n",
    "for week_number in range(1, 10):\n",
    "  week_data = process_week_data(week_number, plays)\n",
    "  all_weeks.append(week_data)\n",
    "\n",
    "all_tracking = pd.concat(all_weeks, ignore_index=True)\n",
    "all_tracking = all_tracking[(all_tracking['club'] != 'football') & (all_tracking['passAttempt'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42799,
     "status": "ok",
     "timestamp": 1732146392404,
     "user": {
      "displayName": "Poker Vision",
      "userId": "17516040938073675309"
     },
     "user_tz": 300
    },
    "id": "h_QFoxCw5kY1",
    "outputId": "17856b7a-38c9-4dee-9c7d-c848e98c596b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 Tensor: torch.Size([762052, 22, 5])\n",
      "Week 1 Indiv Check: tensor([8.0040e+01, 1.6890e+01, 7.2986e-01, 1.4142e-02, 0.0000e+00])\n",
      "Week 2 Tensor: torch.Size([766182, 22, 5])\n",
      "Week 2 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 3 Tensor: torch.Size([758934, 22, 5])\n",
      "Week 3 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 4 Tensor: torch.Size([772004, 22, 5])\n",
      "Week 4 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 5 Tensor: torch.Size([763240, 22, 5])\n",
      "Week 5 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 6 Tensor: torch.Size([774941, 22, 5])\n",
      "Week 6 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 7 Tensor: torch.Size([779178, 22, 5])\n",
      "Week 7 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 8 Tensor: torch.Size([775403, 22, 5])\n",
      "Week 8 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n",
      "Week 9 Tensor: torch.Size([785930, 22, 5])\n",
      "Week 9 Indiv Check: tensor([ 4.8510e+01,  2.8273e+01,  5.2654e-02, -2.8767e-02,  0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "# --- takes ~10mins to run\n",
    "\n",
    "features = [\"x_clean\", \"y_clean\", \"v_x\", \"v_y\", \"defense\"]\n",
    "target_column = \"pff_manZone\"\n",
    "# -- target_column = \"pff_passCoverage\"\n",
    "\n",
    "# looping through weeks & saving each week's training data + validating data\n",
    "for week_eval in range(1, 10):\n",
    "\n",
    "  train_df = all_tracking[all_tracking['week'] != week_eval]\n",
    "  val_df = all_tracking[all_tracking['week'] == week_eval]\n",
    "\n",
    "  train_df = train_df[['frameUniqueId', 'displayName', 'frameId', 'frameType', 'x_clean', 'y_clean', 'v_x', 'v_y', 'defensiveTeam', 'pff_manZone','defense']]\n",
    "  val_df = val_df[['frameUniqueId', 'displayName', 'frameId', 'frameType', 'x_clean', 'y_clean', 'v_x', 'v_y', 'defensiveTeam', 'pff_manZone', 'defense']]\n",
    "\n",
    "  train_features, train_targets = prepare_frame_data(train_df, features, target_column)\n",
    "  val_features, val_targets = prepare_frame_data(val_df, features, target_column)\n",
    "\n",
    "  train_dataset = TensorDataset(train_features, train_targets)\n",
    "  val_dataset = TensorDataset(val_features, val_targets)\n",
    "\n",
    "  print(f\"Week {week_eval} Tensor: {train_features.shape}\")       # should be: torch.Size([X, 22, 5]) where X is num frames, 22 is num plays, 5 is num features (as definied above)\n",
    "  print(f\"Week {week_eval} Indiv Check: {train_features[63][0]}\") # should be: tensor([x_cord, y_cord, v_x,  v_y,  1/0])\n",
    "\n",
    "  # prints the same train_features[63][0] which doesn't give much context to potential errors... to do: change to random\n",
    "  torch.save(train_features, f\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/processed/features_training_week{week_eval}preds.pt\")\n",
    "  torch.save(train_targets, f\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/processed/targets_training_week{week_eval}preds.pt\")\n",
    "\n",
    "  torch.save(val_features, f\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/processed/features_val_week{week_eval}preds.pt\")\n",
    "  torch.save(val_targets, f\"/home/sam/repos/hobby-repos/ExposingCoverageTells-BDB25/data/processed/targets_val_week{week_eval}preds.pt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN9gnHn0houIdvmXCkzq6Ig",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "exposingcoveragetells-bdb25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
