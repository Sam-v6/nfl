{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df8838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  playId    nflId     displayName  frameId    frameType  \\\n",
      "0  2022091200      64  35459.0  Kareem Jackson        1  BEFORE_SNAP   \n",
      "1  2022091200      64  35459.0  Kareem Jackson        2  BEFORE_SNAP   \n",
      "2  2022091200      64  35459.0  Kareem Jackson        3  BEFORE_SNAP   \n",
      "3  2022091200      64  35459.0  Kareem Jackson        4  BEFORE_SNAP   \n",
      "4  2022091200      64  35459.0  Kareem Jackson        5  BEFORE_SNAP   \n",
      "5  2022091200      64  35459.0  Kareem Jackson        6  BEFORE_SNAP   \n",
      "6  2022091200      64  35459.0  Kareem Jackson        7  BEFORE_SNAP   \n",
      "7  2022091200      64  35459.0  Kareem Jackson        8  BEFORE_SNAP   \n",
      "8  2022091200      64  35459.0  Kareem Jackson        9  BEFORE_SNAP   \n",
      "9  2022091200      64  35459.0  Kareem Jackson       10  BEFORE_SNAP   \n",
      "\n",
      "                    time  jerseyNumber club playDirection      x      y     s  \\\n",
      "0  2022-09-13 00:16:03.5          22.0  DEN         right  51.06  28.55  0.72   \n",
      "1  2022-09-13 00:16:03.6          22.0  DEN         right  51.13  28.57  0.71   \n",
      "2  2022-09-13 00:16:03.7          22.0  DEN         right  51.20  28.59  0.69   \n",
      "3  2022-09-13 00:16:03.8          22.0  DEN         right  51.26  28.62  0.67   \n",
      "4  2022-09-13 00:16:03.9          22.0  DEN         right  51.32  28.65  0.65   \n",
      "5    2022-09-13 00:16:04          22.0  DEN         right  51.37  28.68  0.62   \n",
      "6  2022-09-13 00:16:04.1          22.0  DEN         right  51.43  28.71  0.61   \n",
      "7  2022-09-13 00:16:04.2          22.0  DEN         right  51.47  28.75  0.61   \n",
      "8  2022-09-13 00:16:04.3          22.0  DEN         right  51.52  28.80  0.62   \n",
      "9  2022-09-13 00:16:04.4          22.0  DEN         right  51.56  28.84  0.61   \n",
      "\n",
      "      a   dis       o    dir                 event  \n",
      "0  0.37  0.07  246.17  68.34  huddle_break_offense  \n",
      "1  0.36  0.07  245.41  71.21                   NaN  \n",
      "2  0.23  0.07  244.45  69.90                   NaN  \n",
      "3  0.22  0.07  244.45  67.98                   NaN  \n",
      "4  0.34  0.07  245.74  62.83                   NaN  \n",
      "5  0.40  0.06  247.01  59.35                   NaN  \n",
      "6  0.42  0.06  248.57  55.39                   NaN  \n",
      "7  0.49  0.06  251.03  48.20                   NaN  \n",
      "8  0.46  0.06  253.26  43.11                   NaN  \n",
      "9  0.40  0.06  254.75  39.52                   NaN  \n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load data\n",
    "#################################################################\n",
    "\n",
    "import os\n",
    "os.environ[\"NFL_HOME\"] = \"/home/sam/repos/hobby-repos/nfl/\"\n",
    "\n",
    "from common.data_loader import DataLoader\n",
    "\n",
    "# Get raw data\n",
    "loader = DataLoader()\n",
    "games_df, plays_df, players_df, location_data_df = loader.get_data(weeks=[week for week in range (1,10)])\n",
    "\n",
    "print(location_data_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5daad0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering data...\n",
      "Total plays: 16124\n",
      "Total plays after filtering out penalties: 16124\n",
      "Total plays after filtering to valid Man or Zone classifications: 15114\n",
      "Total plays after matching plays_df to location_data_df: 15114\n",
      "       gameId  playId                                    playDescription  \\\n",
      "0  2022102302    2655  (1:54) (Shotgun) J.Burrow pass short middle to...   \n",
      "1  2022091809    3698  (2:13) (Shotgun) J.Burrow pass short right to ...   \n",
      "2  2022103004    3146  (2:00) (Shotgun) D.Mills pass short right to D...   \n",
      "3  2022110610     348  (9:28) (Shotgun) P.Mahomes pass short left to ...   \n",
      "4  2022102700    2799  (2:16) (Shotgun) L.Jackson up the middle to TB...   \n",
      "\n",
      "   quarter  down  yardsToGo possessionTeam defensiveTeam yardlineSide  \\\n",
      "0        3     1         10            CIN           ATL          CIN   \n",
      "1        4     1         10            CIN           DAL          CIN   \n",
      "2        4     3         12            HOU           TEN          HOU   \n",
      "3        1     2         10             KC           TEN          TEN   \n",
      "4        3     2          8            BAL            TB           TB   \n",
      "\n",
      "   yardlineNumber  ... yardsGained  homeTeamWinProbabilityAdded  \\\n",
      "0              21  ...           9                     0.004634   \n",
      "1               8  ...           4                     0.002847   \n",
      "2              20  ...           6                     0.000205   \n",
      "3              23  ...           4                    -0.001308   \n",
      "4              27  ...          -1                     0.027141   \n",
      "\n",
      "   visitorTeamWinProbilityAdded expectedPointsAdded  isDropback  \\\n",
      "0                     -0.004634            0.702717        True   \n",
      "1                     -0.002847           -0.240509        True   \n",
      "2                     -0.000205           -0.218480        True   \n",
      "3                      0.001308           -0.427749        True   \n",
      "4                     -0.027141           -0.638912       False   \n",
      "\n",
      "   pff_runConceptPrimary  pff_runConceptSecondary  pff_runPassOption  \\\n",
      "0                    NaN                      NaN                  0   \n",
      "1                    NaN                      NaN                  0   \n",
      "2                    NaN                      NaN                  0   \n",
      "3                    NaN                      NaN                  0   \n",
      "4                    MAN              READ OPTION                  0   \n",
      "\n",
      "  pff_passCoverage pff_manZone  \n",
      "0          Cover-3        Zone  \n",
      "1         Quarters        Zone  \n",
      "2         Quarters        Zone  \n",
      "3         Quarters        Zone  \n",
      "4          Cover-1         Man  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Filter down plays df to situations we are interested in\n",
    "#################################################################\n",
    "print(\"Filtering data...\")\n",
    "original_play_length = len(plays_df)\n",
    "print(f'Total plays: {original_play_length}')\n",
    "\n",
    "plays_df = plays_df[plays_df['playNullifiedByPenalty'] == 'N']\n",
    "print(f'Total plays after filtering out penalties: {len(plays_df)}')\n",
    "\n",
    "plays_df = plays_df[plays_df['pff_manZone'].isin(['Man', 'Zone'])]\n",
    "print(f'Total plays after filtering to valid Man or Zone classifications: {len(plays_df)}')\n",
    "\n",
    "plays_df = plays_df[plays_df['gameId'].isin(location_data_df['gameId'].unique())]\n",
    "print(f'Total plays after matching plays_df to location_data_df: {len(plays_df)}')\n",
    "\n",
    "print(plays_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12967ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  playId    nflId  frameId    frameType club      x      y\n",
      "0  2022091200      64  35459.0        1  BEFORE_SNAP  DEN  51.06  28.55\n",
      "1  2022091200      64  35459.0        2  BEFORE_SNAP  DEN  51.13  28.57\n",
      "2  2022091200      64  35459.0        3  BEFORE_SNAP  DEN  51.20  28.59\n",
      "3  2022091200      64  35459.0        4  BEFORE_SNAP  DEN  51.26  28.62\n",
      "4  2022091200      64  35459.0        5  BEFORE_SNAP  DEN  51.32  28.65\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Create merged df that has gameId, playId, frameID all before SNAP, with x, y, and offense/defense\n",
    "#################################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy of the location tracking data, cut it down to columns we care about\n",
    "loc_trimmed_df = location_data_df.copy()\n",
    "keep_cols  = [\n",
    "    'gameId',\n",
    "    'playId',\n",
    "    'nflId',\n",
    "    'frameId',\n",
    "    'frameType',\n",
    "    'club',\n",
    "    'x',\n",
    "    'y',\n",
    "]\n",
    "loc_trimmed_df = location_data_df.loc[:, keep_cols]\n",
    "\n",
    "# Cut down location tracking data copy to only before the snap and where the team isn't valid\n",
    "loc_trimmed_df.query('frameType == \"BEFORE_SNAP\" and club != \"football\"', inplace=True)\n",
    "\n",
    "print(loc_trimmed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d678c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  playId possessionTeam defensiveTeam\n",
      "0  2022102302    2655            CIN           ATL\n",
      "1  2022091809    3698            CIN           DAL\n",
      "2  2022103004    3146            HOU           TEN\n",
      "3  2022110610     348             KC           TEN\n",
      "4  2022102700    2799            BAL            TB\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the plays data and cut it down to columns we care about\n",
    "plays_trimmed_df = plays_df.copy()\n",
    "keep_cols_from_plays = ['gameId','playId','possessionTeam', 'defensiveTeam']\n",
    "plays_trimmed_df = plays_trimmed_df.loc[:, keep_cols_from_plays].drop_duplicates()\n",
    "\n",
    "print(plays_trimmed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7282842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              gameId  playId    nflId  frameId      x      y side\n",
      "29059338  2022090800      56  35472.0        1  89.48  29.52  off\n",
      "29059483  2022090800      56  38577.0        1  81.93  28.52  def\n",
      "29059628  2022090800      56  41239.0        1  82.90  29.84  def\n",
      "29059773  2022090800      56  42392.0        1  88.80  30.19  off\n",
      "29059918  2022090800      56  42489.0        1  91.08  28.34  off\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge the two datasets such that we can have the possession and defensive team for each row\n",
    "merged_df = pd.merge(plays_trimmed_df, loc_trimmed_df, on=['gameId', 'playId'], how='inner')\n",
    "\n",
    "# Tag the \"side\" of the player for each row (that being \"off\" or \"def\")\n",
    "merged_df['side'] = np.where(merged_df['club'] == merged_df['possessionTeam'], 'off', 'def')\n",
    "\n",
    "# Drop some columns we don't need anymore\n",
    "merged_df.drop(['possessionTeam', 'defensiveTeam', 'club', 'frameType'], axis=1, inplace=True)\n",
    "\n",
    "# Sort for deterministic frame ordering\n",
    "merged_df = merged_df.sort_values(['gameId','playId','frameId'])\n",
    "\n",
    "# Let's see what we have\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using median sequence length T = 107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decide the target sequence length using the median number of frames per play ---\n",
    "frame_counts = (merged_df\n",
    "                .groupby(['gameId','playId'])['frameId']\n",
    "                .nunique())\n",
    "median_T = int(np.median(frame_counts.values))\n",
    "print(f\"Using median sequence length T = {median_T}\")\n",
    "\n",
    "median_T = 50 # Just setting this to keep play count high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21371d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept plays: 13651\n",
      "Skipped (>11 players): 0\n",
      "Skipped (<50 frames): 1458\n"
     ]
    }
   ],
   "source": [
    "# Built dataset where frame is only 50 frames and each side has exactly 11 players\n",
    "off_series = {}\n",
    "def_series = {}\n",
    "\n",
    "skipped_inccorect_players = []   # plays where offense or defense had >11 unique players\n",
    "skipped_too_short = []           # plays with fewer than median_T frames\n",
    "\n",
    "for (g, p), grp in merged_df.groupby(['gameId','playId'], sort=False):\n",
    "    # Skip if >11 players on either side\n",
    "    off_n = grp.loc[grp['side']=='off', 'nflId'].nunique()\n",
    "    def_n = grp.loc[grp['side']=='def', 'nflId'].nunique()\n",
    "    if off_n != 11 or def_n != 11:\n",
    "        skipped_inccorect_players.append((g,p))\n",
    "        continue\n",
    "\n",
    "    # B) Left->right slot order using median x (tie-break median y) per side\n",
    "    off_stats = (grp[grp['side']=='off']\n",
    "                 .groupby('nflId')\n",
    "                 .agg(x_med=('x','median'), y_med=('y','median'))\n",
    "                 .sort_values(['x_med','y_med']))\n",
    "    def_stats = (grp[grp['side']=='def']\n",
    "                 .groupby('nflId')\n",
    "                 .agg(x_med=('x','median'), y_med=('y','median'))\n",
    "                 .sort_values(['x_med','y_med']))\n",
    "\n",
    "    off_order = off_stats.index.tolist()[:11]\n",
    "    def_order = def_stats.index.tolist()[:11]\n",
    "    if len(off_order) == 0 or len(def_order) == 0:\n",
    "        # nothing useful to build on this play\n",
    "        skipped_too_short.append((g,p))  # treat as unusable\n",
    "        continue\n",
    "\n",
    "    off_id2slot = {pid:i for i,pid in enumerate(off_order)}\n",
    "    def_id2slot = {pid:i for i,pid in enumerate(def_order)}\n",
    "\n",
    "    tmp = grp.copy()\n",
    "    tmp['slot'] = np.where(tmp['side']=='off',\n",
    "                           tmp['nflId'].map(off_id2slot),\n",
    "                           tmp['nflId'].map(def_id2slot))\n",
    "\n",
    "    # Keep only slotted players (0..10)\n",
    "    tmp = tmp[tmp['slot'].between(0,10)]\n",
    "\n",
    "    # Make frame index and pivot\n",
    "    frames = np.sort(tmp['frameId'].unique())\n",
    "    T = len(frames)\n",
    "\n",
    "    # If this play has fewer than the target T, skip it\n",
    "    if T < median_T:\n",
    "        skipped_too_short.append((g,p))\n",
    "        continue\n",
    "\n",
    "    # Optionally trim to the last median_T frames (closest to snap)\n",
    "    if T > median_T:\n",
    "        frames = frames[-median_T:]\n",
    "\n",
    "    goff = tmp[tmp['side']=='off']\n",
    "    gdef = tmp[tmp['side']=='def']\n",
    "\n",
    "    off_x = (goff.pivot_table(index='frameId', columns='slot', values='x')\n",
    "                  .reindex(frames).reindex(columns=range(11), fill_value=np.nan))\n",
    "    off_y = (goff.pivot_table(index='frameId', columns='slot', values='y')\n",
    "                  .reindex(frames).reindex(columns=range(11), fill_value=np.nan))\n",
    "    def_x = (gdef.pivot_table(index='frameId', columns='slot', values='x')\n",
    "                  .reindex(frames).reindex(columns=range(11), fill_value=np.nan))\n",
    "    def_y = (gdef.pivot_table(index='frameId', columns='slot', values='y')\n",
    "                  .reindex(frames).reindex(columns=range(11), fill_value=np.nan))\n",
    "\n",
    "    off_arr = np.stack([off_x.to_numpy(), off_y.to_numpy()], axis=-1)  # (median_T, 11, 2)\n",
    "    def_arr = np.stack([def_x.to_numpy(), def_y.to_numpy()], axis=-1)  # (median_T, 11, 2)\n",
    "\n",
    "    off_series[(g,p)] = off_arr\n",
    "    def_series[(g,p)] = def_arr\n",
    "\n",
    "print(f\"Kept plays: {len(off_series)}\")\n",
    "print(f\"Skipped (>11 players): {len(skipped_inccorect_players)}\")\n",
    "print(f\"Skipped (<{median_T} frames): {len(skipped_too_short)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd0c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PlaysDataset(Dataset):\n",
    "    def __init__(self, off_series, def_series, labels_dict):  # labels_dict[(gameId,playId)] -> 0/1\n",
    "        X_list, y_list = [], []\n",
    "        for key in off_series.keys():\n",
    "            off_arr = off_series[key]     # (T, 11, 2)\n",
    "            def_arr = def_series[key]     # (T, 11, 2)\n",
    "            X = np.concatenate([off_arr, def_arr], axis=1).reshape(off_arr.shape[0], -1)  # (T, 44)\n",
    "            if np.isnan(X).any():\n",
    "                # You can impute; for now, skip if NaNs present\n",
    "                continue\n",
    "            X_list.append(torch.from_numpy(X).float())\n",
    "            y_list.append(torch.tensor(labels_dict[key], dtype=torch.long))\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return (T, F), label\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # All sequences already same T → simple stack\n",
    "    Xs, ys = zip(*batch)\n",
    "    return torch.stack(Xs, dim=0), torch.stack(ys, dim=0)  # (B, T, F), (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ed6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=44, hidden_size=64, num_layers=1, dropout=0.0, bidir=False, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidir,\n",
    "        )\n",
    "        out_dim = hidden_size * (2 if bidir else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(out_dim),\n",
    "            nn.Linear(out_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, F)\n",
    "        out, (h_n, c_n) = self.lstm(x)        # out: (B, T, H)\n",
    "        last = out[:, -1, :]                   # use last timestep representation\n",
    "        logits = self.head(last)               # (B, C)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (Zone, Man): [0.6932453  1.79369251]\n",
      "Epoch 1: val acc = 0.518\n",
      "Epoch 2: val acc = 0.709\n",
      "Epoch 3: val acc = 0.602\n",
      "Epoch 4: val acc = 0.616\n",
      "Epoch 5: val acc = 0.535\n",
      "Epoch 6: val acc = 0.676\n",
      "Epoch 7: val acc = 0.699\n",
      "Epoch 8: val acc = 0.722\n",
      "Epoch 9: val acc = 0.710\n",
      "Epoch 10: val acc = 0.711\n",
      "Epoch 11: val acc = 0.678\n",
      "Epoch 12: val acc = 0.726\n",
      "Epoch 13: val acc = 0.683\n",
      "Epoch 14: val acc = 0.279\n",
      "Epoch 15: val acc = 0.461\n",
      "Epoch 16: val acc = 0.728\n",
      "Epoch 17: val acc = 0.680\n",
      "Epoch 18: val acc = 0.723\n",
      "Epoch 19: val acc = 0.400\n",
      "Epoch 20: val acc = 0.708\n",
      "Epoch 21: val acc = 0.730\n",
      "Epoch 22: val acc = 0.731\n",
      "Epoch 23: val acc = 0.380\n",
      "Epoch 24: val acc = 0.709\n",
      "Epoch 25: val acc = 0.732\n",
      "Epoch 26: val acc = 0.373\n",
      "Epoch 27: val acc = 0.408\n",
      "Epoch 28: val acc = 0.726\n",
      "Epoch 29: val acc = 0.469\n",
      "Epoch 30: val acc = 0.729\n",
      "Epoch 31: val acc = 0.713\n",
      "Epoch 32: val acc = 0.742\n",
      "Epoch 33: val acc = 0.712\n",
      "Epoch 34: val acc = 0.736\n",
      "Epoch 35: val acc = 0.728\n",
      "Epoch 36: val acc = 0.664\n",
      "Epoch 37: val acc = 0.659\n",
      "Epoch 38: val acc = 0.696\n",
      "Epoch 39: val acc = 0.707\n",
      "Epoch 40: val acc = 0.714\n",
      "Epoch 41: val acc = 0.735\n",
      "Epoch 42: val acc = 0.731\n",
      "Epoch 43: val acc = 0.733\n",
      "Epoch 44: val acc = 0.728\n",
      "Epoch 45: val acc = 0.727\n",
      "Epoch 46: val acc = 0.678\n",
      "Epoch 47: val acc = 0.730\n",
      "Epoch 48: val acc = 0.734\n",
      "Epoch 49: val acc = 0.279\n",
      "Epoch 50: val acc = 0.714\n",
      "Epoch 51: val acc = 0.733\n",
      "Epoch 52: val acc = 0.732\n",
      "Epoch 53: val acc = 0.696\n",
      "Epoch 54: val acc = 0.731\n",
      "Epoch 55: val acc = 0.731\n",
      "Epoch 56: val acc = 0.279\n",
      "Epoch 57: val acc = 0.279\n",
      "Epoch 58: val acc = 0.279\n",
      "Epoch 59: val acc = 0.729\n",
      "Epoch 60: val acc = 0.731\n",
      "Epoch 61: val acc = 0.723\n",
      "Epoch 62: val acc = 0.709\n",
      "Epoch 63: val acc = 0.731\n",
      "Epoch 64: val acc = 0.732\n",
      "Epoch 65: val acc = 0.279\n",
      "Epoch 66: val acc = 0.732\n",
      "Epoch 67: val acc = 0.664\n",
      "Epoch 68: val acc = 0.709\n",
      "Epoch 69: val acc = 0.702\n",
      "Epoch 70: val acc = 0.705\n",
      "Epoch 71: val acc = 0.732\n",
      "Epoch 72: val acc = 0.728\n",
      "Epoch 73: val acc = 0.716\n",
      "Epoch 74: val acc = 0.720\n",
      "Epoch 75: val acc = 0.733\n",
      "Epoch 76: val acc = 0.733\n",
      "Epoch 77: val acc = 0.727\n",
      "Epoch 78: val acc = 0.279\n",
      "Epoch 79: val acc = 0.279\n",
      "Epoch 80: val acc = 0.728\n",
      "Epoch 81: val acc = 0.724\n",
      "Epoch 82: val acc = 0.732\n",
      "Epoch 83: val acc = 0.729\n",
      "Epoch 84: val acc = 0.728\n",
      "Epoch 85: val acc = 0.279\n",
      "Epoch 86: val acc = 0.727\n",
      "Epoch 87: val acc = 0.730\n",
      "Epoch 88: val acc = 0.279\n",
      "Epoch 89: val acc = 0.727\n",
      "Epoch 90: val acc = 0.728\n",
      "Epoch 91: val acc = 0.279\n",
      "Epoch 92: val acc = 0.731\n",
      "Epoch 93: val acc = 0.721\n",
      "Epoch 94: val acc = 0.722\n",
      "Epoch 95: val acc = 0.279\n",
      "Epoch 96: val acc = 0.279\n",
      "Epoch 97: val acc = 0.279\n",
      "Epoch 98: val acc = 0.732\n",
      "Epoch 99: val acc = 0.725\n",
      "Epoch 100: val acc = 0.728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Build labels dict mapping (gameId, playId) -> 0/1\n",
    "label_map = {'Man': 1, 'Zone': 0}\n",
    "labels_df = plays_df[['gameId','playId','pff_manZone']].drop_duplicates()\n",
    "labels_dict = {(r.gameId, r.playId): label_map[r.pff_manZone] for r in labels_df.itertuples()}\n",
    "\n",
    "dataset = PlaysDataset(off_series, def_series, labels_dict)\n",
    "idx_train, idx_val = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state=0, stratify=[dataset.y[i].item() for i in range(len(dataset))])\n",
    "\n",
    "subset = torch.utils.data.Subset\n",
    "train_loader = DataLoader(subset(dataset, idx_train), batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader   = DataLoader(subset(dataset, idx_val),   batch_size=128, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMClassifier(input_size=44, hidden_size=64, num_layers=1, dropout=0.0, bidir=False).to(device)\n",
    "\n",
    "\n",
    "# Zone dominates class weighting, calc distro then assign man a higher waiting on the CE loss\n",
    "y_all = np.array([dataset.y[i].item() for i in range(len(dataset))], dtype=int) # Build an array of all dataset labels\n",
    "y_train = y_all[idx_train] # Slice to the training fold\n",
    "classes = np.array([0, 1], dtype=int)  # 0=Zone, 1=Man\n",
    "w = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "print(\"Class weights (Zone, Man):\", w)\n",
    "class_weights = torch.tensor(w, dtype=torch.float32, device=device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Val\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.numel()\n",
    "    print(f\"Epoch {epoch+1}: val acc = {correct/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c9bf5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Zone       0.73      0.98      0.84      1970\n",
      "         Man       0.58      0.09      0.15       761\n",
      "\n",
      "    accuracy                           0.73      2731\n",
      "   macro avg       0.66      0.53      0.50      2731\n",
      "weighted avg       0.69      0.73      0.65      2731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in val_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X).argmax(dim=1)\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_true.extend(y.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_true, all_preds, target_names=[\"Zone\", \"Man\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
